{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wheat Detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ01oM__Ya9F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "b26b76a6-6e84-4d23-f242-b336c8aed811"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects:  25% (1/4)\u001b[K\rremote: Counting objects:  50% (2/4)\u001b[K\rremote: Counting objects:  75% (3/4)\u001b[K\rremote: Counting objects: 100% (4/4)\u001b[K\rremote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 1798 (delta 0), reused 0 (delta 0), pack-reused 1794\u001b[K\n",
            "Receiving objects: 100% (1798/1798), 5.07 MiB | 8.00 MiB/s, done.\n",
            "Resolving deltas: 100% (1171/1171), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0Uxs1fIZqt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install -q kaggle"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0BOjoUUZuW7",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "165736ad-4466-45a5-9834-4926e25811d9"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-db47f236-2d41-497e-8dd4-872913bde7d0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-db47f236-2d41-497e-8dd4-872913bde7d0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"nahilahmed\",\"key\":\"744acb2732214a9f195b8f1249866a84\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aovDIeq8Z2zW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kzy7rOELZ79H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKBp3Q0TaAQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPcLBWcEaUsX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "239b2b6c-e0fa-475f-d969-0d710609ecbe"
      },
      "source": [
        "! kaggle datasets list "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                                                         title                                             size  lastUpdated          downloadCount  \n",
            "----------------------------------------------------------  -----------------------------------------------  -----  -------------------  -------------  \n",
            "roche-data-science-coalition/uncover                        UNCOVER COVID-19 Challenge                       179MB  2020-05-21 18:57:53          16026  \n",
            "rohanrao/chai-time-data-science                             Chai Time Data Science | CTDS.Show                 3MB  2020-06-20 23:01:09            390  \n",
            "andrewmvd/data-analyst-jobs                                 Data Analyst Jobs                                  2MB  2020-07-14 08:37:57             53  \n",
            "mrgeislinger/bart-ridership                                 BART Ridership                                   325MB  2020-07-09 22:28:07              3  \n",
            "moezabid/zillow-all-homes-data                              Zillow All Homes Data                              5MB  2020-07-18 11:44:48             17  \n",
            "tanmoyx/covid19-patient-precondition-dataset                COVID-19 patient pre-condition dataset             7MB  2020-07-18 17:34:49             30  \n",
            "mrmorj/restaurant-recommendation-challenge                  Restaurant Recommendation Challenge              534MB  2020-07-18 16:25:04             20  \n",
            "vishnuvarthanrao/windows-store                              Windows Store                                     93KB  2020-07-07 12:29:07             32  \n",
            "vzrenggamani/hanacaraka                                     Aksara Jawa / Hanacaraka                           9MB  2020-07-10 15:09:31              1  \n",
            "mdabbert/ultimate-ufc-dataset                               Ultimate UFC Dataset                             439KB  2020-07-20 14:38:45            168  \n",
            "garystafford/environmental-sensor-data-132k                 Environmental Sensor Telemetry Data                7MB  2020-07-20 17:18:10              2  \n",
            "benroshan/factors-affecting-campus-placement                Campus Recruitment                                 5KB  2020-04-11 11:09:02          11721  \n",
            "bobbyscience/league-of-legends-diamond-ranked-games-10-min  League of Legends Diamond Ranked Games (10 min)  539KB  2020-04-13 13:53:02           4704  \n",
            "fireballbyedimyrnmom/us-counties-covid-19-dataset           US counties COVID 19 dataset                       3MB  2020-07-20 10:57:52          10229  \n",
            "divyansh22/flight-delay-prediction                          January Flight Delay Prediction                   23MB  2020-04-14 13:15:41           3951  \n",
            "clmentbisaillon/fake-and-real-news-dataset                  Fake and real news dataset                        41MB  2020-03-26 18:51:15           9976  \n",
            "ikiulian/global-hospital-beds-capacity-for-covid19          Global Hospital Beds Capacity (for covid-19)     284KB  2020-04-26 09:39:35           3481  \n",
            "praveengovi/coronahack-chest-xraydataset                    CoronaHack -Chest X-Ray-Dataset                    1GB  2020-03-20 01:26:40           4796  \n",
            "bappekim/air-pollution-in-seoul                             Air Pollution in Seoul                            20MB  2020-04-03 16:33:49           4884  \n",
            "kimjihoo/coronavirusdataset                                 Data Science for COVID-19 (DS4C)                   7MB  2020-07-13 14:07:31          47994  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKGEnCYdk_Y0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e95cf9d-4c8e-4525-ab23-69ff4db07050"
      },
      "source": [
        "%%writefile setup.py\n",
        "\n",
        "import os\n",
        "\n",
        "YOLO_DATA = \"/content/yolov5/wheat_data\"\n",
        "IMAGES_DATA = YOLO_DATA + \"/images\"\n",
        "LABELS_DATA = YOLO_DATA + \"/labels\"\n",
        "\n",
        "IMAGE_TRAIN = IMAGES_DATA + \"/train\"\n",
        "IMAGE_VAL = IMAGES_DATA + \"/validation\"\n",
        "LABEL_TRAIN = LABELS_DATA + \"/train\"\n",
        "LABEL_VAL = LABELS_DATA + \"/validation\"\n",
        "\n",
        "if not os.path.exists(YOLO_DATA):\n",
        "  os.mkdir(YOLO_DATA)\n",
        "\n",
        "if not os.path.exists(IMAGES_DATA):\n",
        "  os.mkdir(IMAGES_DATA)\n",
        "\n",
        "if not os.path.exists(LABELS_DATA):\n",
        "  os.mkdir(LABELS_DATA)\n",
        "\n",
        "if not os.path.exists(IMAGE_TRAIN):\n",
        "  os.mkdir(IMAGE_TRAIN)\n",
        "\n",
        "if not os.path.exists(IMAGE_VAL):\n",
        "  os.mkdir(IMAGE_VAL)\n",
        "\n",
        "if not os.path.exists(LABEL_TRAIN):\n",
        "  os.mkdir(LABEL_TRAIN)\n",
        "\n",
        "if not os.path.exists(LABEL_VAL):\n",
        "  os.mkdir(LABEL_VAL)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing setup.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAlY2dgWlBtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1lD9-0oqC79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_data(data,data_type=\"train\"):\n",
        "  for _,row in tqdm(data.iterrows(),total=len(data)):\n",
        "    image_id = row[0]\n",
        "    bboxes = row[1]\n",
        "    yolo_data=[]\n",
        "    for bbox in bboxes:\n",
        "      x,y,w,h = bbox \n",
        "      x_center = (x + w)/2\n",
        "      y_center = (y + h)/2\n",
        "\n",
        "      x_center, y_center, w, h = x_center/1024, y_center/1024, w/1024, h/1024\n",
        "      yolo_data.append([0,x_center,y_center,w,h])\n",
        "\n",
        "    yolo_data = np.array(yolo_data)\n",
        "    np.savetxt(\n",
        "        os.path.join(YOLO_DATA,\"labels/{}/{}.txt\".format(data_type,image_id)),\n",
        "        yolo_data,\n",
        "        fmt = [\"%d\", \"%f\", \"%f\", \"%f\", \"%f\"]\n",
        "    )\n",
        "    shutil.copyfile(\n",
        "        os.path.join(INPUT_PATH,\"train/{}.jpg\".format(image_id)),\n",
        "        os.path.join(IMAGES_DATA,\"{}/{}.jpg\".format(data_type,image_id)),\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdHR5VpfrLqR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8616a7e6-fd57-4fec-b3ff-05e134d37aed"
      },
      "source": [
        "process_data(df_train, \"train\")\n",
        "process_data(df_valid, \"validation\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3035/3035 [00:04<00:00, 618.37it/s]\n",
            "100%|██████████| 338/338 [00:00<00:00, 420.13it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwhFcKoRv8BS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm global-wheat-detection.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ibkl--BwAux",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "114a6ccc-6fd9-4455-e8e1-4f4e22a36d20"
      },
      "source": [
        "cd yolov5/wheat_data/images/train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/yolov5/wheat_data/images/train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgEEaczVwRNq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e33cd488-ad06-4c0a-9456-780516809dcd"
      },
      "source": [
        "%%writefile preparedata.py\n",
        "\n",
        "import kaggle\n",
        "import pandas as pd\n",
        "import os\n",
        "import ast\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import shutil\n",
        "from sklearn import model_selection\n",
        "import zipfile\n",
        "\n",
        "\n",
        "DOWNLOAD_PATH = \"/content\"\n",
        "INPUT_PATH = \"/content/input\"\n",
        "\n",
        "YOLO_DATA = \"/content/yolov5/wheat_data\"\n",
        "IMAGES_DATA = YOLO_DATA + \"/images\"\n",
        "LABELS_DATA = YOLO_DATA + \"/labels\"\n",
        "\n",
        "def process_data(data,data_type=\"train\"):\n",
        "  for _,row in tqdm(data.iterrows(),total=len(data)):\n",
        "    image_id = row[0]\n",
        "    bboxes = row[1]\n",
        "    yolo_data=[]\n",
        "    for bbox in bboxes:\n",
        "      x,y,w,h = bbox \n",
        "      x_center = (x + w)/2\n",
        "      y_center = (y + h)/2\n",
        "\n",
        "      x_center, y_center, w, h = x_center/1024, y_center/1024, w/1024, h/1024\n",
        "      yolo_data.append([0,x_center,y_center,w,h])\n",
        "\n",
        "    yolo_data = np.array(yolo_data)\n",
        "    np.savetxt(\n",
        "        os.path.join(YOLO_DATA,\"labels/{}/{}.txt\".format(data_type,image_id)),\n",
        "        yolo_data,\n",
        "        fmt = [\"%d\", \"%f\", \"%f\", \"%f\", \"%f\"]\n",
        "    )\n",
        "    shutil.copyfile(\n",
        "        os.path.join(INPUT_PATH,\"train/{}.jpg\".format(image_id)),\n",
        "        os.path.join(IMAGES_DATA,\"{}/{}.jpg\".format(data_type,image_id)),\n",
        "    )\n",
        "\n",
        "\n",
        "kaggle.api.authenticate()\n",
        "kaggle.api.competition_download_files(\"global-wheat-detection\", path=DOWNLOAD_PATH, quiet=False)\n",
        "\n",
        "with zipfile.ZipFile(DOWNLOAD_PATH + \"/global-wheat-detection.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(INPUT_PATH)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  df = pd.read_csv(os.path.join(INPUT_PATH,\"train.csv\"))\n",
        "  df.bbox = df.bbox.apply(ast.literal_eval)\n",
        "  df = df.groupby(\"image_id\")[\"bbox\"].apply(list).reset_index(name=\"bboxes\")\n",
        "  print(df.head(10))\n",
        "\n",
        "  df_train, df_valid = model_selection.train_test_split(\n",
        "      df,\n",
        "      test_size=0.1,\n",
        "      shuffle=True,\n",
        "      random_state = 42\n",
        "  )\n",
        "\n",
        "  df_train = df_train.reset_index(drop=True)\n",
        "  df_valid = df_valid.reset_index(drop=True)\n",
        "\n",
        "  process_data(df_train, \"train\")\n",
        "  process_data(df_valid, \"validation\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing preparedata.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uYqQgoN2BzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! python setup.py"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je840NzM2UmU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "5512c079-5c01-4edc-b03f-523c6a7ed94d"
      },
      "source": [
        "! python preparedata.py"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading global-wheat-detection.zip to /content\n",
            " 95% 579M/607M [00:12<00:01, 27.4MB/s]\n",
            "100% 607M/607M [00:12<00:00, 51.8MB/s]\n",
            "    image_id                                             bboxes\n",
            "0  00333207f  [[0, 654, 37, 111], [0, 817, 135, 98], [0, 192...\n",
            "1  005b0d8bb  [[765.0, 879.0, 116.0, 79.0], [84.0, 539.0, 15...\n",
            "2  006a994f7  [[437.0, 988.0, 98.0, 36.0], [309.0, 527.0, 11...\n",
            "3  00764ad5d  [[89.0, 256.0, 113.0, 107.0], [216.0, 282.0, 1...\n",
            "4  00b5fefed  [[709.0, 97.0, 204.0, 105.0], [775.0, 250.0, 1...\n",
            "5  00b70a919  [[147.0, 46.0, 80.0, 88.0], [0.0, 230.0, 69.0,...\n",
            "6  00e903abe  [[0, 103, 22, 72], [0, 8, 76, 90], [59, 64, 61...\n",
            "7  00ea5e5ee  [[327.0, 3.0, 35.0, 49.0], [928.0, 0.0, 90.0, ...\n",
            "8  010b216d4  [[367.0, 293.0, 113.0, 110.0], [0.0, 556.0, 91...\n",
            "9  010c93b99  [[185.0, 559.0, 146.0, 113.0], [691.0, 809.0, ...\n",
            "100% 3035/3035 [00:04<00:00, 690.41it/s]\n",
            "100% 338/338 [00:00<00:00, 737.66it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmuUYwlz4P6D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83480139-dd7f-454e-bd6c-f48e26f7fbb5"
      },
      "source": [
        "cd yolov5/"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/yolov5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnBjJwj0ybka",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab253a59-d778-40a7-dce1-1315e07ceaba"
      },
      "source": [
        "%%writefile wheat.yaml\n",
        "\n",
        "train: wheat_data/images/train/\n",
        "val: wheat_data/images/validation/\n",
        "nc: 1\n",
        "names: [\"wheat\"]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing wheat.yaml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIfc88UQzCG5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "fe7d98d5-f130-45ea-b7c4-fa2321f54172"
      },
      "source": [
        "!cat wheat.yaml"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train: wheat_data/images/train/\n",
            "val: wheat_data/images/validation/\n",
            "nc: 1\n",
            "names: [\"wheat\"]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKt98zRr65kr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9a72deb-467e-416d-cead-3dbeb8bb0bb2"
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCN89hOYzUfg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99c4fc13-22ff-4612-b178-d347466cd2fb"
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/yolov5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRtmj3WP2xRJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b33c63cb-e5c9-47a5-aadc-325e4e00a61c"
      },
      "source": [
        "!pip install -qr requirements.txt  # install dependencies (ignore errors)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▏                              | 10kB 20.1MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20kB 4.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30kB 6.1MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 51kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 61kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 71kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 81kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 92kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 102kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 112kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 122kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 133kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 143kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 153kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 163kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 174kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 184kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 194kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 204kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 215kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 225kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 235kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 245kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 256kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 266kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276kB 7.0MB/s \n",
            "\u001b[?25h  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1XnYv544Nns",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7aeeb9d-d956-4610-8a79-6b87830b23bf"
      },
      "source": [
        "! python train.py --img 1024 --batch 8 --epochs 10 --data wheat.yaml --cfg models/yolov5s.yaml --name wm --weights yolov5s.pt --device 0"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
            "Using CUDA device0 _CudaDeviceProperties(name='Tesla K80', total_memory=11441MB)\n",
            "\n",
            "Namespace(batch_size=8, bucket='', cache_images=False, cfg='models/yolov5s.yaml', data='wheat.yaml', device='0', epochs=10, evolve=False, hyp='', img_size=[1024, 1024], local_rank=-1, multi_scale=False, name='wm', noautoanchor=False, nosave=False, notest=False, rect=False, resume=False, single_cls=False, sync_bn=False, total_batch_size=8, weights='yolov5s.pt', world_size=1)\n",
            "Start Tensorboard with \"tensorboard --logdir=runs\", view at http://localhost:6006/\n",
            "2020-07-21 05:50:30.988160: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "Hyperparameters {'optimizer': 'SGD', 'lr0': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'giou': 0.05, 'cls': 0.58, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.014, 'hsv_s': 0.68, 'hsv_v': 0.36, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.5, 'shear': 0.0}\n",
            "Overriding models/yolov5s.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
            "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
            " 18                -1  1      2322  torch.nn.modules.conv.Conv2d            [128, 18, 1, 1]               \n",
            " 19                -2  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 20          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 21                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
            " 22                -1  1      4626  torch.nn.modules.conv.Conv2d            [256, 18, 1, 1]               \n",
            " 23                -2  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 24          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 25                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
            " 26                -1  1      9234  torch.nn.modules.conv.Conv2d            [512, 18, 1, 1]               \n",
            " 27      [-1, 22, 18]  1         0  models.yolo.Detect                      [1, [[116, 90, 156, 198, 373, 326], [30, 61, 62, 45, 59, 119], [10, 13, 16, 30, 33, 23]]]\n",
            "Model Summary: 191 layers, 7.25509e+06 parameters, 7.25509e+06 gradients\n",
            "\n",
            "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   279    0   279    0     0   2762      0 --:--:-- --:--:-- --:--:--  2762\n",
            "100   408    0   408    0     0    695      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 14.4M    0 14.4M    0     0  12.7M      0 --:--:--  0:00:01 --:--:-- 12.7M\n",
            "Downloading https://drive.google.com/uc?export=download&id=1R5T6rIyy3lLwgFXNms8whc-387H0tMQO as yolov5s.pt... Done (3.4s)\n",
            "Scanning images: 100% 3035/3035 [00:00<00:00, 3933.71it/s]\n",
            "Scanning labels wheat_data/labels/train.cache (3035 found, 0 missing, 0 empty, 0 duplicate, for 3035 images): 100% 3035/3035 [00:00<00:00, 9419.52it/s]\n",
            "Scanning images: 100% 338/338 [00:00<00:00, 4028.60it/s]\n",
            "Scanning labels wheat_data/labels/validation.cache (338 found, 0 missing, 0 empty, 0 duplicate, for 338 images): 100% 338/338 [00:00<00:00, 8811.89it/s]\n",
            "\n",
            "Analyzing anchors... Best Possible Recall (BPR) = 0.9992\n",
            "Image sizes 1024 train, 1024 test\n",
            "Using 2 dataloader workers\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "       0/9     6.66G   0.09182    0.1874         0    0.2792       144      1024: 100% 380/380 [07:08<00:00,  1.13s/it]\n",
            "               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100% 43/43 [00:58<00:00,  1.35s/it]\n",
            "                 all         338    1.51e+04      0.0825      0.0453      0.0208     0.00346\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "       1/9     6.66G   0.07812    0.2007         0    0.2788       207      1024: 100% 380/380 [06:53<00:00,  1.09s/it]\n",
            "               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100% 43/43 [00:43<00:00,  1.01s/it]\n",
            "                 all         338    1.51e+04      0.0746       0.104      0.0213     0.00378\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "       2/9     6.66G   0.07794    0.1977         0    0.2756       180      1024: 100% 380/380 [06:52<00:00,  1.09s/it]\n",
            "               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100% 43/43 [00:45<00:00,  1.06s/it]\n",
            "                 all         338    1.51e+04      0.0725      0.0636      0.0213     0.00358\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "       3/9     6.66G   0.07597    0.1959         0    0.2719       160      1024: 100% 380/380 [06:49<00:00,  1.08s/it]\n",
            "               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100% 43/43 [00:43<00:00,  1.01s/it]\n",
            "                 all         338    1.51e+04      0.0895      0.0851      0.0273     0.00477\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "       4/9     6.66G   0.07512    0.1965         0    0.2716       219      1024: 100% 380/380 [06:51<00:00,  1.08s/it]\n",
            "               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100% 43/43 [00:43<00:00,  1.01s/it]\n",
            "                 all         338    1.51e+04       0.089       0.103      0.0305     0.00509\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "       5/9     6.66G   0.07455    0.1954         0    0.2699       331      1024: 100% 380/380 [06:50<00:00,  1.08s/it]\n",
            "               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100% 43/43 [00:44<00:00,  1.04s/it]\n",
            "                 all         338    1.51e+04      0.0907       0.176      0.0424     0.00777\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "       6/9     6.66G   0.07418    0.1951         0    0.2693       139      1024: 100% 380/380 [06:49<00:00,  1.08s/it]\n",
            "               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100% 43/43 [00:45<00:00,  1.05s/it]\n",
            "                 all         338    1.51e+04      0.0863       0.207      0.0389     0.00683\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "       7/9     6.66G   0.07409    0.1937         0    0.2678        54      1024: 100% 380/380 [06:50<00:00,  1.08s/it]\n",
            "               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100% 43/43 [00:46<00:00,  1.08s/it]\n",
            "                 all         338    1.51e+04      0.0833        0.22      0.0374     0.00654\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "       8/9     6.66G   0.07359    0.1882         0    0.2618       255      1024: 100% 380/380 [06:50<00:00,  1.08s/it]\n",
            "               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100% 43/43 [00:44<00:00,  1.04s/it]\n",
            "                 all         338    1.51e+04       0.081       0.215      0.0343     0.00594\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
            "       9/9     6.66G   0.07353    0.1889         0    0.2624       112      1024: 100% 380/380 [06:49<00:00,  1.08s/it]\n",
            "               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100% 43/43 [00:45<00:00,  1.06s/it]\n",
            "                 all         338    1.51e+04       0.107       0.146      0.0458      0.0081\n",
            "Optimizer stripped from runs/exp0_wm/weights/last_wm.pt, 14.9MB\n",
            "Optimizer stripped from runs/exp0_wm/weights/best_wm.pt, 14.9MB\n",
            "No handles with labels found to put in legend.\n",
            "10 epochs completed in 1.276 hours.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqCALzJAOOj2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "578699e6-23f5-4444-b2b5-dcc077812f4c"
      },
      "source": [
        "! python detect.py --source /content/input/test --weights /content/yolov5/runs/exp0_wm/weights/best_wm.pt --conf 0.4"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.4, device='', img_size=640, iou_thres=0.5, output='inference/output', save_txt=False, source='/content/input/test', update=False, view_img=False, weights=['/content/yolov5/runs/exp0_wm/weights/best_wm.pt'])\n",
            "Using CUDA device0 _CudaDeviceProperties(name='Tesla K80', total_memory=11441MB)\n",
            "\n",
            "Fusing layers... Model Summary: 140 layers, 7.24652e+06 parameters, 6.61683e+06 gradients\n",
            "image 1/10 /content/input/test/2fd875eaa.jpg: 640x640 Done. (0.034s)\n",
            "image 2/10 /content/input/test/348a992bb.jpg: 640x640 Done. (0.033s)\n",
            "image 3/10 /content/input/test/51b3e36ab.jpg: 640x640 Done. (0.034s)\n",
            "image 4/10 /content/input/test/51f1be19e.jpg: 640x640 Done. (0.033s)\n",
            "image 5/10 /content/input/test/53f253011.jpg: 640x640 Done. (0.033s)\n",
            "image 6/10 /content/input/test/796707dd7.jpg: 640x640 Done. (0.033s)\n",
            "image 7/10 /content/input/test/aac893a91.jpg: 640x640 Done. (0.033s)\n",
            "image 8/10 /content/input/test/cb8d261a3.jpg: 640x640 Done. (0.033s)\n",
            "image 9/10 /content/input/test/cc3532ff6.jpg: 640x640 Done. (0.033s)\n",
            "image 10/10 /content/input/test/f5a1f0358.jpg: 640x640 Done. (0.033s)\n",
            "Results saved to /content/yolov5/inference/output\n",
            "Done. (0.774s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GNHt6H1PiHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}